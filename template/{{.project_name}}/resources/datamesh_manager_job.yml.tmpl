# The datamesh_manager job, sends datacontract.yml + dataproduct.yml to Data Mesh Manager
resources:
  jobs:
    datamesh_manager_job:
      name: datamesh_manager_job

      schedule:
        quartz_cron_expression: '0 * * * * ?'
        timezone_id: Europe/Amsterdam

      email_notifications:
        on_failure:
          - stefan.negele@innoq.com

      tasks:

        - task_key: main_task
          job_cluster_key: job_cluster
          python_wheel_task:
            package_name: {{.project_name}}
            entry_point: datamesh_manager
            parameters: 
              - "/Workspace${workspace.file_path}"

          libraries:
            - whl: ../dist/*.whl
            - pypi:
                package: "requests==2.31.0"
            - pypi:
                package: "pyyaml==6.0.1"

      job_clusters:
        - job_cluster_key: job_cluster
          new_cluster:
            spark_version: 13.3.x-scala2.12
            node_type_id: Standard_D3_v2
            data_security_mode: SINGLE_USER
            num_workers: 1
